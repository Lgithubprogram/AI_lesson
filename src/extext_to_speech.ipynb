{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "此模型基于大一所学，代码为开源代码",
   "id": "80955580dc3a5486"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T03:08:28.588729Z",
     "start_time": "2024-11-13T03:08:28.582715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from pypinyin import lazy_pinyin\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        # 读取文件列表并解析\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 获取音频文件路径和对应的文本\n",
    "        file_path, text = self.file_list[index]\n",
    "        \n",
    "        # 将中文文本转换为拼音\n",
    "        pinyin_text = \" \".join(lazy_pinyin(text))\n",
    "        \n",
    "        # 加载音频文件，提取 Mel 频谱\n",
    "        mel_spec = self.load_mel_spec(file_path)\n",
    "        \n",
    "        return mel_spec, pinyin_text\n",
    "\n",
    "    def load_mel_spec(self, file_path):\n",
    "        # 读取音频并提取 Mel 频谱\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        mel_spec = self.compute_mel_spectrogram(waveform, sample_rate)\n",
    "        return mel_spec\n",
    "\n",
    "    def compute_mel_spectrogram(self, waveform, sample_rate):\n",
    "        # 使用 torchaudio 提取 Mel 频谱\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate)\n",
    "        mel_spec = mel_transform(waveform)\n",
    "        return mel_spec\n"
   ],
   "id": "3a9548cffce6ac9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T03:11:15.328657Z",
     "start_time": "2024-11-13T03:11:15.267464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "from torchaudio.pipelines import TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 加载预训练的 Tacotron 2 模型\n",
    "tacotron2 = TACOTRON2_WAVERNN_PHONE_LJSPEECH.get_text_to_spectrogram()\n",
    "wavernn = TACOTRON2_WAVERNN_PHONE_LJSPEECH.get_vocoder()\n",
    "\n",
    "# 假设你有自己的数据集\n",
    "dataset = MyDataset()  # 这里要定义自己的数据集类\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ],
   "id": "3d5ae44fbdd5206f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MyDataset.__init__() missing 1 required positional argument: 'file_list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m wavernn \u001B[38;5;241m=\u001B[39m TACOTRON2_WAVERNN_PHONE_LJSPEECH\u001B[38;5;241m.\u001B[39mget_vocoder()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 假设你有自己的数据集\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mMyDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 这里要定义自己的数据集类\u001B[39;00m\n\u001B[0;32m     11\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: MyDataset.__init__() missing 1 required positional argument: 'file_list'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T03:08:28.673982300Z",
     "start_time": "2024-11-12T17:02:44.571295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 设定较小的学习率\n",
    "optimizer = optim.Adam(tacotron2.parameters(), lr=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 微调 Tacotron 2 和 WaveRNN\n",
    "for epoch in range(10):  # 训练 10 个 epoch\n",
    "    for mel_spec, text in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 使用模型生成 Mel 频谱\n",
    "        mel_spec_pred, _ = tacotron2(text)\n",
    "        \n",
    "        # 计算损失并反向传播\n",
    "        loss = loss_fn(mel_spec_pred, mel_spec)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ],
   "id": "e4d0028a1bfe1d1f",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 生成 Mel 频谱\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[1;32m----> 7\u001B[0m     mel_spec, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtacotron2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_tensor\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Application\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchaudio\\models\\tacotron2.py:1032\u001B[0m, in \u001B[0;36mTacotron2.infer\u001B[1;34m(self, tokens, lengths)\u001B[0m\n\u001B[0;32m   1007\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[0;32m   1008\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minfer\u001B[39m(\u001B[38;5;28mself\u001B[39m, tokens: Tensor, lengths: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor, Tensor]:\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Using Tacotron2 for inference. The input is a batch of encoded\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;124;03m    sentences (``tokens``) and its corresponding lengths (``lengths``). The\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m \u001B[38;5;124;03m    output is the generated mel spectrograms, its corresponding lengths, and\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;124;03m                `(n_batch, max of mel_specgram_lengths, max of lengths)`.\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1032\u001B[0m     n_batch, max_length \u001B[38;5;241m=\u001B[39m \u001B[43mtokens\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n\u001B[0;32m   1033\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lengths \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m         lengths \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([max_length])\u001B[38;5;241m.\u001B[39mexpand(n_batch)\u001B[38;5;241m.\u001B[39mto(tokens\u001B[38;5;241m.\u001B[39mdevice, tokens\u001B[38;5;241m.\u001B[39mdtype)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T03:08:28.691131700Z",
     "start_time": "2024-11-12T17:02:22.127813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设你已经完成了训练\n",
    "text = \"zhe shi yi ge ce shi\"  # 输入的文本（拼音）\n",
    "mel_spec, _ = tacotron2.infer(text)  # 生成 Mel 频谱\n",
    "\n",
    "# 使用 WaveNet vocoder 生成音频波形\n",
    "waveform = wavernn(mel_spec)\n",
    "\n",
    "# 保存或播放生成的音频\n",
    "torchaudio.save(\"output.wav\", waveform, sample_rate=22050)\n"
   ],
   "id": "59e8b72b8ded013d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mel_spec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 生成音频波形\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[1;32m----> 6\u001B[0m     waveform \u001B[38;5;241m=\u001B[39m wavernn(\u001B[43mmel_spec\u001B[49m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 保存或播放音频\u001B[39;00m\n\u001B[0;32m      9\u001B[0m torchaudio\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m, waveform, sample_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m22050\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'mel_spec' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:26:11.144781Z",
     "start_time": "2024-11-19T17:26:11.131960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "appid = '20241112002201004'\n",
    "appkey = 'rRqX2uzmWqLqplMV_M6c'\n",
    "\n",
    "\n",
    "client = ZhipuAI(api_key=\"b69f0e809e6601a4ca5c9d9407b8ce2b.Nwpl24uMiaVFZ6Im\") "
   ],
   "id": "2fc2638c182984f7",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
